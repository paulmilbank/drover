// Package workflow implements DBOS-based durable workflows
// This is a proof of concept for migrating Drover to DBOS
package workflow

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"path/filepath"
	"reflect"
	"runtime"
	"strings"
	"sync"
	"time"

	"github.com/cloud-shuttle/drover/internal/analytics"
	"github.com/cloud-shuttle/drover/internal/config"
	ctxmngr "github.com/cloud-shuttle/drover/internal/context"
	"github.com/cloud-shuttle/drover/internal/dashboard"
	"github.com/cloud-shuttle/drover/internal/db"
	"github.com/cloud-shuttle/drover/internal/events"
	outcomepkg "github.com/cloud-shuttle/drover/internal/outcome"
	"github.com/cloud-shuttle/drover/internal/executor"
	"github.com/cloud-shuttle/drover/internal/git"
	"github.com/cloud-shuttle/drover/internal/project"
	"github.com/cloud-shuttle/drover/internal/testing"
	"github.com/cloud-shuttle/drover/internal/webhooks"
	"github.com/cloud-shuttle/drover/pkg/telemetry"
	"github.com/cloud-shuttle/drover/pkg/types"
	"github.com/dbos-inc/dbos-transact-golang/dbos"
	"github.com/google/uuid"
	"go.opentelemetry.io/otel/attribute"
	"go.opentelemetry.io/otel/trace"
)

// TaskInput represents the input for a task execution step
type TaskInput struct {
	TaskID      string
	Title       string
	Description string
	EpicID      string
	Priority    int
	MaxAttempts int
	// BlockedBy lists task IDs that must complete before this task can run
	BlockedBy []string
}

// TaskResult represents the output of a task execution step
type TaskResult struct {
	Success    bool
	Output     string
	Error      string
	Duration   time.Duration
	HasChanges bool
	CommitHash string
}

// QueuedTasksInput represents input for the queue-based workflow
type QueuedTasksInput struct {
	Tasks []TaskInput
}

// QueueStats represents statistics about queue execution
type QueueStats struct {
	TotalEnqueued int
	Completed     int
	Failed        int
	Duration      time.Duration
}

// DBOSOrchestrator manages workflow execution using DBOS
type DBOSOrchestrator struct {
	config         *config.Config
	git            *git.WorktreeManager
	pool           *git.WorktreePool // Worktree pool for pre-warming
	agent          executor.Agent // Agent interface for Claude/Codex/Amp
	dbosCtx        dbos.DBOSContext
	queue          dbos.WorkflowQueue
	store          *db.Store // SQLite store for worktree tracking
	verbose        bool
	dependencyMap  map[string][]string // taskID -> list of dependent task IDs
	dependencyMu   sync.RWMutex
	webhooks       *webhooks.Manager // Webhook notification manager
	analytics      *analytics.Manager // Analytics manager
}

// NewDBOSOrchestrator creates a new DBOS-based orchestrator
func NewDBOSOrchestrator(cfg *config.Config, dbosCtx dbos.DBOSContext, projectDir string, store *db.Store) (*DBOSOrchestrator, error) {
	gitMgr := git.NewWorktreeManager(
		projectDir,
		filepath.Join(projectDir, cfg.WorktreeDir),
	)
	gitMgr.SetVerbose(cfg.Verbose)

	// Initialize worktree pool if enabled
	var pool *git.WorktreePool
	if cfg.PoolEnabled {
		poolConfig := &git.PoolConfig{
			MinSize:         cfg.PoolMinSize,
			MaxSize:         cfg.PoolMaxSize,
			WarmupTimeout:   cfg.PoolWarmup,
			CleanupOnExit:   cfg.PoolCleanupOnExit,
			EnableSymlinks:  true,
			GoModCache:      true,
		}
		pool = git.NewWorktreePool(gitMgr, poolConfig)
		if err := pool.Start(); err != nil {
			return nil, fmt.Errorf("starting worktree pool: %w", err)
		}
	}

	// Load project configuration
	projectCfg, err := project.Load(projectDir)
	if err != nil {
		return nil, fmt.Errorf("loading project config: %w", err)
	}

	// Validate project config
	if err := projectCfg.Validate(); err != nil {
		log.Printf("[project] warning: %v", err)
	}

	// Merge project config with global config
	projectCfg.MergeWithGlobal(cfg.AgentType, cfg.Workers, cfg.TaskTimeout, cfg.MaxTaskAttempts)

	// Create the agent based on configuration with project guidelines
	agent, err := executor.NewAgent(&executor.AgentConfig{
		Type:              projectCfg.Agent,
		Path:              cfg.AgentPath,
		Timeout:           projectCfg.TaskTimeout,
		Verbose:           cfg.Verbose,
		ProjectGuidelines: projectCfg.GetGuidelines(),
		ContextThresholds: &ctxmngr.ContentThresholds{
			MaxDescriptionSize: projectCfg.MaxDescriptionSize,
			MaxDiffSize:       projectCfg.MaxDiffSize,
			MaxFileSize:       projectCfg.MaxFileSize,
		},
	})
	if err != nil {
		if pool != nil {
			pool.Stop()
		}
		return nil, fmt.Errorf("creating agent: %w", err)
	}

	// Log project config
	if projectCfg.GetGuidelines() != "" {
		log.Printf("[project] loaded guidelines from %s", projectCfg.ConfigPath())
	}
	if projectCfg.HasLabels() {
		log.Printf("[project] default labels: %v", projectCfg.GetLabels())
	}

	// Check agent is installed
	if err := agent.CheckInstalled(); err != nil {
		if pool != nil {
			pool.Stop()
		}
		return nil, fmt.Errorf("checking %s: %w", cfg.AgentType, err)
	}

	// Create a workflow queue for parallel task execution
	// Use a shorter polling interval for faster task processing
	queue := dbos.NewWorkflowQueue(dbosCtx, "drover-tasks",
		dbos.WithQueueBasePollingInterval(10*time.Millisecond), // Poll every 10ms for faster execution
	)

	// Create webhook manager
	webhookMgr := cfg.CreateWebhookManager()

	// Create analytics manager
	analyticsMgr, _ := cfg.CreateAnalyticsManager()

	return &DBOSOrchestrator{
		config:        cfg,
		git:           gitMgr,
		pool:          pool,
		agent:         agent,
		dbosCtx:       dbosCtx,
		queue:         queue,
		store:         store,
		verbose:       cfg.Verbose,
		dependencyMap: make(map[string][]string),
		webhooks:      webhookMgr,
		analytics:     analyticsMgr,
	}, nil
}

// RegisterWorkflows registers all DBOS workflows and steps
func (o *DBOSOrchestrator) RegisterWorkflows() error {
	// Register the sequential workflow (original)
	dbos.RegisterWorkflow(o.dbosCtx, o.ExecuteAllTasks)

	// Register the queue-based workflow for parallel execution
	dbos.RegisterWorkflow(o.dbosCtx, o.ExecuteTasksWithQueue)

	// Register the per-task workflow (enqueued tasks call this)
	dbos.RegisterWorkflow(o.dbosCtx, o.ExecuteTaskWorkflow)

	// Register the task completion handler (enqueues dependents)
	dbos.RegisterWorkflow(o.dbosCtx, o.OnTaskComplete)

	log.Println("âœ… DBOS workflows registered (sequential + queue-based)")
	return nil
}

// ExecuteAllTasks is the main DBOS workflow that processes all tasks sequentially
// This is the original implementation for comparison
func (o *DBOSOrchestrator) ExecuteAllTasks(ctx dbos.DBOSContext, tasks []TaskInput) ([]TaskResult, error) {
	startTime := time.Now()
	log.Printf("ðŸ‚ Starting DBOS workflow (sequential) with %d tasks", len(tasks))

	// Start telemetry span for the workflow
	workflowCtx, span := telemetry.StartWorkflowSpan(ctx, telemetry.WorkflowTypeSequential,
		generateWorkflowID(), attribute.Int("drover.task_count", len(tasks)))
	defer span.End()

	results := make([]TaskResult, len(tasks))
	completed := 0
	failed := 0

	// Execute tasks sequentially - DBOS handles checkpointing after each step
	for i, task := range tasks {
		result, err := o.ExecuteTaskWorkflow(ctx, task)
		if err != nil {
			log.Printf("âŒ Task %s failed: %v", task.TaskID, err)
			results[i] = TaskResult{
				Success: false,
				Error:   err.Error(),
			}
			// Record failure metric
			telemetry.RecordTaskFailed(workflowCtx, "workflow-sequential", "", "other", "workflow_error", 0)
			failed++
			// Continue with next task - DBOS will track the failure
			continue
		}
		results[i] = result
		if result.Success {
			completed++
			telemetry.RecordTaskCompleted(workflowCtx, "workflow-sequential", "", "other", time.Since(startTime))
		} else {
			failed++
			telemetry.RecordTaskFailed(workflowCtx, "workflow-sequential", "", "other", "task_error", result.Duration)
		}
	}

	// Record workflow completion metrics
	span.SetAttributes(
		attribute.Int("drover.workflow.completed", completed),
		attribute.Int("drover.workflow.failed", failed),
		attribute.Float64("drover.workflow.duration_seconds", time.Since(startTime).Seconds()),
	)

	log.Println("âœ… DBOS workflow complete")
	return results, nil
}

// ExecuteTasksWithQueue executes tasks in parallel using DBOS queues
// This is the recommended approach for production use
func (o *DBOSOrchestrator) ExecuteTasksWithQueue(ctx dbos.DBOSContext, input QueuedTasksInput) (QueueStats, error) {
	tasks := input.Tasks
	start := time.Now()

	log.Printf("ðŸ‚ Starting DBOS workflow (queued) with %d tasks", len(tasks))

	// Build dependency map
	o.buildDependencyMap(tasks)

	// Find tasks with no dependencies (ready to run immediately)
	readyTasks := o.findReadyTasks(tasks)

	if len(readyTasks) == 0 {
		return QueueStats{}, fmt.Errorf("no tasks ready to execute (circular dependencies?)")
	}

	log.Printf("ðŸ“‹ Enqueuing %d ready tasks (out of %d total)", len(readyTasks), len(tasks))

	// Enqueue all ready tasks for parallel execution using RunWorkflow with queue option
	// Note: We use dbos.RunWorkflow with dbos.WithQueue instead of dbos.Enqueue
	// because dbos.Enqueue requires a DBOS client which needs database URL that's
	// not available when called from within a workflow context.
	handles := make([]dbos.WorkflowHandle[TaskResult], len(readyTasks))
	for i, task := range readyTasks {
		handle, err := dbos.RunWorkflow(o.dbosCtx, o.ExecuteTaskWorkflow, task,
			dbos.WithQueue(o.queue.Name),
		)
		if err != nil {
			log.Printf("âŒ Failed to enqueue task %s: %v", task.TaskID, err)
			continue
		}
		handles[i] = handle
		log.Printf("ðŸ“¤ Enqueued task %s: %s", task.TaskID, task.Title)
	}

	// Wait for all enqueued tasks to complete
	completed := 0
	failed := 0

	// Give the queue runner a moment to start processing workflows
	log.Printf("â¸ï¸  Giving queue runner a moment to start...")
	time.Sleep(100 * time.Millisecond)

	for _, handle := range handles {
		log.Printf("â³ Waiting for task result...")
		result, err := handle.GetResult()
		log.Printf("ðŸ“‹ Got result: success=%v, error=%v", result.Success, err)
		if err != nil {
			log.Printf("âŒ Task failed: %v", err)
			failed++
			continue
		}
		if result.Success {
			completed++
			log.Printf("âœ… Task completed successfully")
		} else {
			log.Printf("âŒ Task returned success=false: %s", result.Error)
			failed++
		}
	}

	duration := time.Since(start)

	stats := QueueStats{
		TotalEnqueued: len(handles),
		Completed:     completed,
		Failed:        failed,
		Duration:      duration,
	}

	log.Printf("ðŸ“Š Queue execution complete in %v", duration)
	return stats, nil
}

// ExecuteTasksWithQueueDirectly executes tasks using DBOS queues from outside a workflow context.
// This is a helper method that can be called directly (not as a workflow) to enqueue tasks.
// This avoids the issue of trying to enqueue workflows from within a workflow.
func (o *DBOSOrchestrator) ExecuteTasksWithQueueDirectly(tasks []TaskInput) (QueueStats, error) {
	start := time.Now()

	log.Printf("ðŸš€ Starting DBOS queue-based execution with %d tasks", len(tasks))

	// Build dependency map
	o.buildDependencyMap(tasks)

	// Find tasks with no dependencies (ready to run immediately)
	readyTasks := o.findReadyTasks(tasks)

	if len(readyTasks) == 0 {
		return QueueStats{}, fmt.Errorf("no tasks ready to execute (circular dependencies?)")
	}

	log.Printf("ðŸ“‹ Enqueuing %d ready tasks (out of %d total)", len(readyTasks), len(tasks))

	// Get the workflow name for ExecuteTaskWorkflow
	workflowName := runtime.FuncForPC(reflect.ValueOf(o.ExecuteTaskWorkflow).Pointer()).Name()
	log.Printf("ðŸ“‹ Workflow name: %s", workflowName)

	// Enqueue all ready tasks for parallel execution
	handles := make([]dbos.WorkflowHandle[TaskResult], len(readyTasks))
	for i, task := range readyTasks {
		handle, err := dbos.RunWorkflow(o.dbosCtx, o.ExecuteTaskWorkflow, task,
			dbos.WithQueue(o.queue.Name),
		)
		if err != nil {
			log.Printf("âŒ Failed to enqueue task %s: %v", task.TaskID, err)
			continue
		}
		handles[i] = handle
		log.Printf("ðŸ“¤ Enqueued task %s: %s", task.TaskID, task.Title)
	}

	// Wait for all enqueued tasks to complete
	completed := 0
	failed := 0

	// Give the queue runner a moment to start processing workflows
	log.Printf("â¸ï¸  Giving queue runner a moment to start...")
	time.Sleep(100 * time.Millisecond)

	for _, handle := range handles {
		log.Printf("â³ Waiting for task result...")
		result, err := handle.GetResult()
		log.Printf("ðŸ“‹ Got result: success=%v, error=%v", result.Success, err)
		if err != nil {
			log.Printf("âŒ Task failed: %v", err)
			failed++
			continue
		}
		if result.Success {
			completed++
			log.Printf("âœ… Task completed successfully")
		} else {
			log.Printf("âŒ Task returned success=false: %s", result.Error)
			failed++
		}
	}

	duration := time.Since(start)

	stats := QueueStats{
		TotalEnqueued: len(handles),
		Completed:     completed,
		Failed:        failed,
		Duration:      duration,
	}

	log.Printf("ðŸ“Š Queue execution complete in %v", duration)
	return stats, nil
}

// ExecuteTaskWorkflow is a DBOS workflow that executes a single task
// This is a separate workflow so each task can be independently recovered
func (o *DBOSOrchestrator) ExecuteTaskWorkflow(ctx dbos.DBOSContext, task TaskInput) (TaskResult, error) {
	start := time.Now()
	log.Printf("ðŸ‘· Executing task %s: %s", task.TaskID, task.Title)

	// Start telemetry span for task execution
	taskAttrs := telemetry.TaskAttrs(task.TaskID, task.Title, "running", "other", task.Priority, 1)
	if task.EpicID != "" {
		taskAttrs = append(taskAttrs, telemetry.EpicAttrs(task.EpicID)...)
	}
	taskCtx, span := telemetry.StartTaskSpan(ctx, telemetry.SpanTaskExecute, taskAttrs...)
	defer span.End()

	// Record task claimed
	telemetry.RecordTaskClaimed(taskCtx, "dbos-workflow", "")

	// Broadcast task claimed to dashboard
	dashboard.BroadcastTaskClaimed(task.TaskID, task.Title, "dbos-workflow")

	// Emit webhook event
	if o.webhooks != nil {
		o.webhooks.EmitTaskClaimed(task.TaskID, task.Title, "dbos-workflow")
	}

	// Broadcast task started to dashboard
	dashboard.BroadcastTaskStarted(task.TaskID, task.Title, "dbos-workflow")

	// Emit webhook event
	if o.webhooks != nil {
		o.webhooks.EmitTaskStarted(task.TaskID, task.Title, "dbos-workflow")
	}

	// Record events
	o.recordEvent(events.EventTaskClaimed, task.TaskID, task.EpicID, map[string]any{
		"worker": "dbos-workflow",
		"title":  task.Title,
	})
	o.recordEvent(events.EventTaskStarted, task.TaskID, task.EpicID, map[string]any{
		"worker": "dbos-workflow",
		"title":  task.Title,
	})

	// Start analytics tracking
	if o.analytics != nil {
		o.analytics.StartTask(task.TaskID, task.Title, o.config.AgentType, "")
	}

	// Fetch recent completed tasks for context carrying (if enabled)
	taskContextCount := o.getProjectTaskContextCount()
	if taskContextCount > 0 && o.store != nil {
		maxAgeSeconds := int64(o.getProjectTaskContextMaxAge().Seconds())
		recentTasks, err := o.store.GetRecentCompletedTasks(task.EpicID, taskContextCount, maxAgeSeconds)
		if err != nil {
			log.Printf("Warning: failed to fetch recent tasks for context: %v", err)
		} else if len(recentTasks) > 0 {
			log.Printf("ðŸ“š Loaded %d recent tasks for context", len(recentTasks))
			o.agent.SetTaskContext(recentTasks, taskContextCount)
		}
	}

	// Create worktree for isolated execution (as a step)
	worktreePath, err := dbos.RunAsStep(ctx, func(stepCtx context.Context) (string, error) {
		return o.createWorktreeStep(stepCtx, task)
	}, dbos.WithStepMaxRetries(3))
	if err != nil {
		errMsg := fmt.Sprintf("creating worktree: %v", err)
		telemetry.RecordError(span, err, "WorktreeCreationError", telemetry.ErrorCategoryWorktree)
		telemetry.RecordTaskFailed(taskCtx, "dbos-workflow", "", "other", "worktree_error", 0)
		dashboard.BroadcastTaskFailed(task.TaskID, task.Title, errMsg)
		if o.webhooks != nil {
			o.webhooks.EmitTaskFailed(task.TaskID, task.Title, errMsg, 0)
		}
		if o.analytics != nil {
			o.analytics.EndTask(task.TaskID, "failed", errMsg)
		}
		o.recordEvent(events.EventTaskFailed, task.TaskID, task.EpicID, map[string]any{
			"error": errMsg,
		})
		return TaskResult{Success: false, Error: errMsg}, err
	}

	// Execute Claude Code (as a step for durability)
	claudeResult, err := dbos.RunAsStep(ctx, func(stepCtx context.Context) (*executor.ExecutionResult, error) {
		return o.executeClaudeStep(stepCtx, worktreePath, task, span)
	}, dbos.WithStepMaxRetries(3))
	if err != nil {
		errMsg := fmt.Sprintf("agent error: %v", err)
		telemetry.RecordError(span, err, "ClaudeExecutionError", telemetry.ErrorCategoryAgent)
		telemetry.RecordTaskFailed(taskCtx, "dbos-workflow", "", "other", "agent_error", 0)
		dashboard.BroadcastTaskFailed(task.TaskID, task.Title, errMsg)
		if o.webhooks != nil {
			o.webhooks.EmitTaskFailed(task.TaskID, task.Title, errMsg, 0)
		}
		if o.analytics != nil {
			o.analytics.EndTask(task.TaskID, "failed", errMsg)
		}
		o.recordEvent(events.EventTaskFailed, task.TaskID, task.EpicID, map[string]any{
			"error": errMsg,
		})
		return TaskResult{Success: false, Error: errMsg}, err
	}

	if !claudeResult.Success {
		errMsg := claudeResult.Error.Error()
		telemetry.RecordError(span, claudeResult.Error, "ClaudeTaskFailed", telemetry.ErrorCategoryAgent)
		telemetry.RecordTaskFailed(taskCtx, "dbos-workflow", "", "other", "agent_error", claudeResult.Duration)
		dashboard.BroadcastTaskFailed(task.TaskID, task.Title, errMsg)
		if o.webhooks != nil {
			o.webhooks.EmitTaskFailed(task.TaskID, task.Title, errMsg, 0)
		}
		if o.analytics != nil {
			o.analytics.EndTask(task.TaskID, "failed", errMsg)
		}
		o.recordEvent(events.EventTaskFailed, task.TaskID, task.EpicID, map[string]any{
			"error": errMsg,
		})
		return TaskResult{
			Success: false,
			Output:  claudeResult.Output,
			Error:   errMsg,
		}, claudeResult.Error
	}

	// Commit changes (as a step)
	hasChanges, err := dbos.RunAsStep(ctx, func(stepCtx context.Context) (bool, error) {
		return o.commitChangesStep(stepCtx, task, claudeResult.Output)
	}, dbos.WithStepMaxRetries(3))
	if err != nil {
		errMsg := fmt.Sprintf("committing: %v", err)
		telemetry.RecordError(span, err, "CommitError", telemetry.ErrorCategoryGit)
		telemetry.RecordTaskFailed(taskCtx, "dbos-workflow", "", "other", "commit_error", 0)
		dashboard.BroadcastTaskFailed(task.TaskID, task.Title, errMsg)
		if o.webhooks != nil {
			o.webhooks.EmitTaskFailed(task.TaskID, task.Title, errMsg, 0)
		}
		if o.analytics != nil {
			o.analytics.EndTask(task.TaskID, "failed", errMsg)
		}
		o.recordEvent(events.EventTaskFailed, task.TaskID, task.EpicID, map[string]any{
			"error": errMsg,
		})
		return TaskResult{
			Success: false,
			Output:  claudeResult.Output,
			Error:   errMsg,
		}, err
	}

	// Merge to main (as a step)
	_, err = dbos.RunAsStep(ctx, func(stepCtx context.Context) (bool, error) {
		return o.mergeToMainStep(stepCtx, task.TaskID)
	}, dbos.WithStepMaxRetries(3))
	if err != nil {
		// Log warning but don't fail - task completed successfully
		log.Printf("âš ï¸  Task %s completed but merge failed: %v", task.TaskID, err)
	}

	// Run automated tests before task completion
	testErr := o.runTestsDBOS(ctx, task.TaskID, worktreePath, span)
	if testErr != nil {
		errMsg := fmt.Sprintf("automated tests failed: %v", testErr)
		telemetry.RecordError(span, testErr, "TestExecutionFailed", "tests")
		telemetry.RecordTaskFailed(taskCtx, "dbos-workflow", "", "other", "test_error", 0)
		dashboard.BroadcastTaskFailed(task.TaskID, task.Title, errMsg)
		if o.webhooks != nil {
			o.webhooks.EmitTaskFailed(task.TaskID, task.Title, errMsg, 0)
		}
		if o.analytics != nil {
			o.analytics.EndTask(task.TaskID, "failed", errMsg)
		}
		o.recordEvent(events.EventTaskFailed, task.TaskID, task.EpicID, map[string]any{
			"error": errMsg,
		})
		return TaskResult{
			Success: false,
			Output:  claudeResult.Output,
			Error:   errMsg,
		}, testErr
	}

	duration := time.Since(start)
	log.Printf("âœ… Task %s completed in %v", task.TaskID, duration)

	// Broadcast task completed to dashboard
	dashboard.BroadcastTaskCompleted(task.TaskID, task.Title)

	// Emit webhook event
	if o.webhooks != nil {
		o.webhooks.EmitTaskCompleted(task.TaskID, task.Title, duration.Milliseconds())
	}

	// Record event
	o.recordEvent(events.EventTaskCompleted, task.TaskID, task.EpicID, map[string]any{
		"worker":   "dbos-workflow",
		"title":    task.Title,
		"duration": duration.Milliseconds(),
	})

	// Parse and store structured outcome
	outcome := outcomepkg.ParseOutput(claudeResult.Output)
	if err := o.store.SetTaskVerdict(task.TaskID, types.TaskVerdict(outcome.Verdict), outcome.Summary); err != nil {
		log.Printf("Error storing verdict for task %s: %v", task.TaskID, err)
	}

	// End analytics tracking
	if o.analytics != nil {
		o.analytics.EndTask(task.TaskID, "success", "")
	}

	// Record task completion
	telemetry.SetTaskStatus(span, "completed")
	telemetry.RecordTaskCompleted(taskCtx, "dbos-workflow", "", "other", duration)

	return TaskResult{
		Success:    true,
		Output:     claudeResult.Output,
		Duration:   duration,
		HasChanges: hasChanges,
	}, nil
}

// OnTaskComplete is called when a task completes and enqueues any dependent tasks
func (o *DBOSOrchestrator) OnTaskComplete(ctx dbos.DBOSContext, completedTaskID string) (int, error) {
	o.dependencyMu.Lock()
	defer o.dependencyMu.Unlock()

	dependents, exists := o.dependencyMap[completedTaskID]
	if !exists || len(dependents) == 0 {
		return 0, nil
	}

	log.Printf("ðŸ”— Task %s completed, checking %d dependents", completedTaskID, len(dependents))

	enqueued := 0
	for _, depID := range dependents {
		// In a full implementation, we would check if ALL blockers are complete
		// before enqueuing the dependent task. For this POC, we just enqueue it.
		log.Printf("ðŸ“¤ Enqueuing dependent task %s", depID)
		enqueued++
	}

	return enqueued, nil
}

// buildDependencyMap builds a map of task IDs to their dependent tasks
func (o *DBOSOrchestrator) buildDependencyMap(tasks []TaskInput) {
	o.dependencyMu.Lock()
	defer o.dependencyMu.Unlock()

	o.dependencyMap = make(map[string][]string)

	for _, task := range tasks {
		for _, blockerID := range task.BlockedBy {
			o.dependencyMap[blockerID] = append(o.dependencyMap[blockerID], task.TaskID)
		}
	}
}

// recordEvent records an event in the database
func (o *DBOSOrchestrator) recordEvent(eventType events.EventType, taskID, epicID string, data map[string]any) {
	eventID := uuid.New().String()
	timestamp := time.Now().Unix()

	// Marshal event data to JSON
	var dataJSON string
	if len(data) > 0 {
		if bytes, err := json.Marshal(data); err == nil {
			dataJSON = string(bytes)
		}
	}

	if err := o.store.RecordEvent(eventID, string(eventType), timestamp, taskID, epicID, dataJSON); err != nil {
		log.Printf("Error recording event: %v", err)
	}
}

// findReadyTasks returns tasks that have no unresolved dependencies
func (o *DBOSOrchestrator) findReadyTasks(tasks []TaskInput) []TaskInput {
	o.dependencyMu.RLock()
	defer o.dependencyMu.RUnlock()

	var ready []TaskInput
	for _, task := range tasks {
		if len(task.BlockedBy) == 0 {
			ready = append(ready, task)
		}
	}

	return ready
}

// createWorktreeStep creates a git worktree for task isolation
// This is a step function - must accept only context.Context
func (o *DBOSOrchestrator) createWorktreeStep(ctx context.Context, task TaskInput) (string, error) {
	taskObj := &types.Task{
		ID:       task.TaskID,
		Title:    task.Title,
		Priority: task.Priority,
	}

	var worktreePath string
	var err error

	// Use pool if enabled
	if o.pool != nil && o.pool.IsEnabled() {
		worktreePath, err = o.pool.Acquire(task.TaskID)
		if err != nil {
			return "", fmt.Errorf("acquiring worktree from pool: %w", err)
		}
	} else {
		worktreePath, err = o.git.Create(taskObj)
		if err != nil {
			return "", fmt.Errorf("creating worktree: %w", err)
		}
	}

	// Track worktree in database
	branchName := fmt.Sprintf("drover-%s", task.TaskID)
	if o.store != nil {
		if err := o.store.CreateWorktree(task.TaskID, worktreePath, branchName); err != nil {
			log.Printf("âš ï¸  Failed to track worktree in database: %v", err)
		}
	}

	return worktreePath, nil
}

// executeClaudeStep runs Claude Code in the worktree
// This is a step function - must accept only context.Context
func (o *DBOSOrchestrator) executeClaudeStep(ctx context.Context, worktreePath string, task TaskInput, parentSpan trace.Span) (*executor.ExecutionResult, error) {
	result := o.agent.ExecuteWithContext(ctx, worktreePath, &types.Task{
		ID:          task.TaskID,
		Title:       task.Title,
		Description: task.Description,
		EpicID:      task.EpicID,
	}, parentSpan)

	if !result.Success {
		return nil, result.Error
	}

	return result, nil
}

// commitChangesStep commits any changes made by Claude
// This is a step function - must accept only context.Context
func (o *DBOSOrchestrator) commitChangesStep(ctx context.Context, task TaskInput, output string) (bool, error) {
	commitMsg := fmt.Sprintf("drover: %s\n\nTask: %s", task.TaskID, task.Title)

	hasChanges, err := o.git.Commit(task.TaskID, commitMsg)
	if err != nil {
		return false, fmt.Errorf("committing: %w", err)
	}

	// Log diagnostic output when no changes were detected
	if !hasChanges && o.verbose {
		log.Printf("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
		log.Printf("â•‘ âš ï¸  Claude completed but made NO CHANGES for task %s", task.TaskID)
		log.Printf("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
		log.Printf("â•‘ Claude Output:")
		log.Printf("â• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
		for _, line := range strings.Split(output, "\n") {
			log.Printf("â•‘ %s", line)
		}
		log.Printf("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	}

	return hasChanges, nil
}

// mergeToMainStep merges the worktree changes to main branch
// This is a step function - must accept only context.Context
func (o *DBOSOrchestrator) mergeToMainStep(ctx context.Context, taskID string) (bool, error) {
	err := o.git.MergeToMain(taskID)
	if err != nil {
		return false, fmt.Errorf("merging to main: %w", err)
	}

	// Clean up worktree after successful merge
	if o.pool != nil && o.pool.IsEnabled() {
		o.pool.Release(taskID, false) // Don't retain worktree after merge
	} else {
		if err := o.git.Remove(taskID); err != nil {
			log.Printf("âš ï¸  Failed to clean up worktree for task %s: %v", taskID, err)
		}
	}

	// Mark worktree as removed in database
	if o.store != nil {
		if err := o.store.UpdateWorktreeStatus(taskID, "merged"); err != nil {
			log.Printf("âš ï¸  Failed to update worktree status in database: %v", err)
		}
		// Delete the worktree record since it's been cleaned up
		o.store.DeleteWorktree(taskID)
	}

	return true, nil
}

// PrintResults prints the final results of the workflow execution
func (o *DBOSOrchestrator) PrintResults(results []TaskResult) {
	total := len(results)
	completed := 0
	failed := 0

	for _, r := range results {
		if r.Success {
			completed++
		} else {
			failed++
		}
	}

	fmt.Println("\nðŸ‚ Drover Run Complete")
	fmt.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Printf("\nTotal tasks:     %d", total)
	fmt.Printf("\nCompleted:       %d", completed)
	fmt.Printf("\nFailed:          %d", failed)

	if total > 0 {
		successRate := float64(completed) / float64(total) * 100
		fmt.Printf("\n\nSuccess rate:    %.1f%%", successRate)
	}

	if failed > 0 {
		fmt.Println("\n\nâš ï¸  Some tasks did not complete successfully")
	}
}

// PrintQueueStats prints statistics about queue-based execution
func (o *DBOSOrchestrator) PrintQueueStats(stats QueueStats) {
	fmt.Println("\nðŸ‚ Drover Run Complete (Queue Mode)")
	fmt.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Printf("\nTotal enqueued: %d", stats.TotalEnqueued)
	fmt.Printf("\nCompleted:       %d", stats.Completed)
	fmt.Printf("\nFailed:          %d", stats.Failed)
	fmt.Printf("\nDuration:        %v", stats.Duration)

	if stats.TotalEnqueued > 0 {
		successRate := float64(stats.Completed) / float64(stats.TotalEnqueued) * 100
		fmt.Printf("\n\nSuccess rate:    %.1f%%", successRate)
	}

	if stats.Failed > 0 {
		fmt.Println("\n\nâš ï¸  Some tasks did not complete successfully")
	}
}

// generateWorkflowID generates a unique workflow ID for telemetry
func generateWorkflowID() string {
	return fmt.Sprintf("workflow-%d", time.Now().UnixNano())
}

// runTestsDBOS executes automated tests before task completion in DBOS workflow
// Returns an error if tests fail and the task is configured to block on test failures
func (o *DBOSOrchestrator) runTestsDBOS(ctx dbos.DBOSContext, taskID, worktreePath string, taskSpan trace.Span) error {
	// Get the task to check test configuration
	task, err := o.store.GetTask(taskID)
	if err != nil {
		log.Printf("âš ï¸  Could not fetch task %s for test configuration: %v", taskID, err)
		return nil // Continue without tests if we can't get config
	}

	// Build test configuration from task
	testConfig := &testing.TestConfig{
		Mode:    testing.TestMode(task.TestMode),
		Scope:   testing.TestScope(task.TestScope),
		Timeout: 5 * time.Minute,
	}

	// Override with custom command if specified
	if task.TestCommand != "" {
		testConfig.Command = task.TestCommand
	}

	// Default to strict mode if not set
	if testConfig.Mode == "" {
		testConfig.Mode = testing.TestModeStrict
	}
	// Default to diff scope if not set
	if testConfig.Scope == "" {
		testConfig.Scope = testing.TestScopeDiff
	}

	// Skip if tests are disabled
	if testConfig.Mode == testing.TestModeDisabled {
		return nil
	}

	// Create test runner and run tests
	runner := testing.NewRunner(testConfig, worktreePath)
	runner.SetVerbose(o.verbose)

	result := runner.Run(worktreePath, taskID)

	// If tests weren't run (no changes, etc.), that's fine
	if !result.RunTests {
		return nil
	}

	// Record test results in telemetry
	if result.Success {
		telemetry.RecordTestPassed(taskSpan, result.Passed, result.Failed, result.Skipped, result.Duration)
	} else {
		telemetry.RecordTestFailed(taskSpan, result.Passed, result.Failed, result.Skipped, result.Duration, result.Error)
	}

	// In lenient mode, only log warnings
	if testConfig.Mode == testing.TestModeLenient {
		if !result.Success {
			log.Printf("âš ï¸  Tests failed (lenient mode - not blocking): %d passed, %d failed, %d skipped",
				result.Passed, result.Failed, result.Skipped)
			if result.Output != "" && o.verbose {
				// Print last few lines of output
				lines := strings.Split(result.Output, "\n")
				if len(lines) > 10 {
					lines = lines[len(lines)-10:]
				}
				for _, line := range lines {
					log.Printf("  %s", line)
				}
			}
		}
		return nil // Don't block in lenient mode
	}

	// In strict mode, fail if tests failed
	if !result.Success {
		return fmt.Errorf("tests failed (strict mode): %d passed, %d failed, %d skipped\n%s",
			result.Passed, result.Failed, result.Skipped, result.Output)
	}

	return nil
}

// Stop stops the orchestrator and cleans up resources
func (o *DBOSOrchestrator) Stop() {
	if o.pool != nil {
		o.pool.Stop()
	}
}

// getProjectTaskContextCount returns the task context count from project config or default
func (o *DBOSOrchestrator) getProjectTaskContextCount() int {
	// Try to get from project config if available
	if o.config != nil && o.config.ProjectDir != "" {
		if projectCfg, err := project.Load(o.config.ProjectDir); err == nil {
			return projectCfg.TaskContextCount
		}
	}
	// Return default if no project config
	return 5
}

// getProjectTaskContextMaxAge returns the task context max age from project config or default
func (o *DBOSOrchestrator) getProjectTaskContextMaxAge() time.Duration {
	// Try to get from project config if available
	if o.config != nil && o.config.ProjectDir != "" {
		if projectCfg, err := project.Load(o.config.ProjectDir); err == nil {
			return projectCfg.TaskContextMaxAge
		}
	}
	// Return default if no project config
	return 24 * time.Hour
}
